{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "3bw24ChJc8O_"
   },
   "source": [
    "# Librerías"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!pip install wikipedia-api\n",
    "#!pip install wordcloud\n",
    "#!pip install -U spacy\n",
    "#!python -m spacy download en_core_web_md\n",
    "#!pip install -U gensim\n",
    "#!pip install fuzzywuzzy\n",
    "#!pip install python-Levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 223
    },
    "colab_type": "code",
    "executionInfo": {
     "elapsed": 1053,
     "status": "ok",
     "timestamp": 1544636694883,
     "user": {
      "displayName": "Cristina Ríos",
      "photoUrl": "",
      "userId": "02000832313296606614"
     },
     "user_tz": -60
    },
    "id": "ynEgXMf8cu90",
    "outputId": "1c32a169-6c32-4281-d461-0524e31fb5e2"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ana\\AppData\\Local\\Continuum\\anaconda3\\lib\\site-packages\\fuzzywuzzy\\fuzz.py:11: UserWarning: Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning\n",
      "  warnings.warn('Using slow pure-python SequenceMatcher. Install python-Levenshtein to remove this warning')\n",
      "[nltk_data] Downloading package sentiwordnet to\n",
      "[nltk_data]     C:\\Users\\Ana\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package sentiwordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import nltk\n",
    "import re\n",
    "import spacy\n",
    "import en_core_web_md\n",
    "import gensim\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models.word2vec import Word2Vec\n",
    "from fuzzywuzzy import fuzz\n",
    "from fuzzywuzzy import process\n",
    "import seaborn as sns\n",
    "import string\n",
    "import random\n",
    "import wikipediaapi\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud, STOPWORDS\n",
    "from nltk.corpus import sentiwordnet as swn\n",
    "nltk.download('sentiwordnet')\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import requests\n",
    "from bs4 import BeautifulSoup"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "_o1qBzqUdA1T"
   },
   "source": [
    "## ESLÓGANES"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Web scraping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<!DOCTYPE html>\n",
      "<html lang=\"en-US\">\n",
      " <head>\n",
      "  <meta charset=\"utf-8\"/>\n",
      "  <meta content=\"width=device-width, initial-scale=1, minimum-scale=1\" name=\"viewport\"/>\n",
      "  <link href=\"http://gmpg.org/xfn/11\" rel=\"profile\"/>\n",
      "  <link href=\"http://www.adglitz.com/xmlrpc.php\" rel=\"pingback\"/>\n",
      "  <title>\n",
      "   Ad slogans taglines punchlines. 500+ slogans from famous commercials advertisements adverts. All time great database of ad slogans – Adglitz\n",
      "  </title>\n",
      "  <link href=\"//s.w.org\" rel=\"dns-prefetch\">\n",
      "   <link hr\n"
     ]
    }
   ],
   "source": [
    "# Conexión con la página web de la que se quieren extraer los eslóganes\n",
    "\n",
    "page = requests.get(\"http://www.adglitz.com/blog/2010/07/ad-slogans-taglines-punchlines-500-slogans-from-famous-commercials-advertisements-adverts-all-time-great-database-of-ad-slogans\")\n",
    "\n",
    "\n",
    "# Obtención del código fuente\n",
    "\n",
    "soup = BeautifulSoup(page.content, 'html.parser')\n",
    "\n",
    "print(soup.prettify()[:500])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A-1 makes hamburgers taste like steakburgers',\n",
       " 'Abbey National advertising slogans',\n",
       " 'Get the Abbey habit',\n",
       " 'Because life’s complicated enough',\n",
       " 'advertising slogans',\n",
       " 'Access takes the waiting out of wanting',\n",
       " 'Makes sensible buying simple',\n",
       " 'Access – Your Flexible Friend',\n",
       " 'Does you does, or does you don’t take Access?',\n",
       " 'Your flexible friend']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selección de la información de interés (indicar la etiqueta que contiene la info)\n",
    "\n",
    "allwithstrong = [j.get_text() for j in soup.find_all('span', style=\"color: black;\")[2:]]\n",
    "\n",
    "allwithstrong[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['advertisingslogans',\n",
       " '500commercialslogans,taglines,punchlinesandmarketingmottos.',\n",
       " 'advertslogans,',\n",
       " 'taglines,',\n",
       " 'punchlines',\n",
       " 'mottos',\n",
       " 'sloganortagline',\n",
       " 'A-1SteakSauceadvertisingtagline',\n",
       " 'AbbeyNationaladvertisingslogans',\n",
       " 'AccessCreditCardsloganadvertisingslogans']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Filtrar el nombre de la marca (contenida en la subetiqueta <strong>)\n",
    "\n",
    "# Lista de los valores a eliminar\n",
    "\n",
    "strongs = [i.get_text().replace(\" \", \"\") for i in soup.find_all('strong')]\n",
    "\n",
    "strongs[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['A-1 makes hamburgers taste like steakburgers',\n",
       " 'Get the Abbey habit',\n",
       " 'Because life’s complicated enough',\n",
       " 'Access takes the waiting out of wanting',\n",
       " 'Makes sensible buying simple',\n",
       " 'Access – Your Flexible Friend',\n",
       " 'Does you does, or does you don’t take Access?',\n",
       " 'Your flexible friend',\n",
       " 'The True Definition of Luxury. Yours.',\n",
       " 'Fresh Squeezed Glaciers']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Selección de los eslóganes (exclusión de las marcas)\n",
    "\n",
    "alls = [x for x in allwithstrong if x.replace(\" \", \"\") not in strongs]\n",
    "\n",
    "alls[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "692"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad total de eslóganes\n",
    "\n",
    "len(alls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "HBxfTUICmSGi"
   },
   "outputs": [],
   "source": [
    "# Visualizar el contenido completo de todas las columnas\n",
    "\n",
    "pd.set_option('display.max_colwidth', -1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slogans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1 makes hamburgers taste like steakburgers</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Get the Abbey habit</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because life’s complicated enough</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Access takes the waiting out of wanting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Makes sensible buying simple</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        slogans\n",
       "0  A-1 makes hamburgers taste like steakburgers\n",
       "1  Get the Abbey habit                         \n",
       "2  Because life’s complicated enough           \n",
       "3  Access takes the waiting out of wanting     \n",
       "4  Makes sensible buying simple                "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dataframe con los eslóganes extraídos mediande escrapeo\n",
    "\n",
    "slogansDF = pd.DataFrame({\"slogans\": alls})\n",
    "\n",
    "slogansDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ESQUELETOS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Análisis morfológico"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['CC', 'CD', 'DT', 'EX', 'IN', 'MD', 'PDT', 'POS', 'PRP', 'PRP$', 'RB', 'RBR', 'RBS', 'RP', 'UH', 'TO', 'WDT', 'WP', 'WP$', 'WRB', 'LS', ',', '.']\n"
     ]
    }
   ],
   "source": [
    "# Selección de los tags que deben aparecer en los esqueletos \n",
    "\n",
    "pos_in = [\"CC\", \"CD\", \"DT\", \"EX\", \"IN\", \"MD\", \"PDT\", \"POS\", \"PRP\", \"PRP$\", \"RB\", \"RBR\", \"RBS\", \"RP\", \"UH\", \"TO\", \"WDT\", \"WP\", \"WP$\", \"WRB\", \"LS\", \",\", \".\"]\n",
    "\n",
    "print(pos_in)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slogans</th>\n",
       "      <th>sloganTagged</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1 makes hamburgers taste like steakburgers</td>\n",
       "      <td>[(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Get the Abbey habit</td>\n",
       "      <td>[(get, VB), (the, DT), (abbey, NN), (habit, NN)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because life’s complicated enough</td>\n",
       "      <td>[(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Access takes the waiting out of wanting</td>\n",
       "      <td>[(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Makes sensible buying simple</td>\n",
       "      <td>[(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        slogans  \\\n",
       "0  A-1 makes hamburgers taste like steakburgers   \n",
       "1  Get the Abbey habit                            \n",
       "2  Because life’s complicated enough              \n",
       "3  Access takes the waiting out of wanting        \n",
       "4  Makes sensible buying simple                   \n",
       "\n",
       "                                                                                   sloganTagged  \n",
       "0  [(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]   \n",
       "1  [(get, VB), (the, DT), (abbey, NN), (habit, NN)]                                              \n",
       "2  [(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]              \n",
       "3  [(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]  \n",
       "4  [(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]                                    "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Añadir una columna al dataframe inicial con el análisis POS_TAG de los eslóganes (división por palabras y transformación a minúsculas)\n",
    "\n",
    "slogansDF['sloganTagged'] = slogansDF['slogans'].apply(lambda x: nltk.pos_tag(nltk.tokenize.word_tokenize(x.lower())))\n",
    "\n",
    "slogansDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Construcción de esqueletos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slogans</th>\n",
       "      <th>sloganTagged</th>\n",
       "      <th>sloganSkeleton</th>\n",
       "      <th>sloganAuxi</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1 makes hamburgers taste like steakburgers</td>\n",
       "      <td>[(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, like, NNS]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, NNS]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Get the Abbey habit</td>\n",
       "      <td>[(get, VB), (the, DT), (abbey, NN), (habit, NN)]</td>\n",
       "      <td>[VB, the, NN, NN]</td>\n",
       "      <td>[VB, NN, NN]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because life’s complicated enough</td>\n",
       "      <td>[(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]</td>\n",
       "      <td>[because, NN, NNP, NN, VBD, enough]</td>\n",
       "      <td>[NN, NNP, NN, VBD]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Access takes the waiting out of wanting</td>\n",
       "      <td>[(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]</td>\n",
       "      <td>[NN, VBZ, the, VBG, out, of, VBG]</td>\n",
       "      <td>[NN, VBZ, VBG, VBG]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Makes sensible buying simple</td>\n",
       "      <td>[(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        slogans  \\\n",
       "0  A-1 makes hamburgers taste like steakburgers   \n",
       "1  Get the Abbey habit                            \n",
       "2  Because life’s complicated enough              \n",
       "3  Access takes the waiting out of wanting        \n",
       "4  Makes sensible buying simple                   \n",
       "\n",
       "                                                                                   sloganTagged  \\\n",
       "0  [(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]    \n",
       "1  [(get, VB), (the, DT), (abbey, NN), (habit, NN)]                                               \n",
       "2  [(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]               \n",
       "3  [(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]   \n",
       "4  [(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]                                     \n",
       "\n",
       "                        sloganSkeleton                sloganAuxi  \n",
       "0  [JJ, VBZ, NNS, VBP, like, NNS]       [JJ, VBZ, NNS, VBP, NNS]  \n",
       "1  [VB, the, NN, NN]                    [VB, NN, NN]              \n",
       "2  [because, NN, NNP, NN, VBD, enough]  [NN, NNP, NN, VBD]        \n",
       "3  [NN, VBZ, the, VBG, out, of, VBG]    [NN, VBZ, VBG, VBG]       \n",
       "4  [VBZ, JJ, NN, NN]                    [VBZ, JJ, NN, NN]         "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creo dos listas vacías\n",
    "\n",
    "allSkeletons = []\n",
    "allAuxis = []\n",
    "\n",
    "# Recorro cada sloganTagged\n",
    "\n",
    "for index,slogan in enumerate(slogansDF.sloganTagged):\n",
    "    \n",
    "    # Creo dos listas vacías (esqueletos y palabras auxiliares(keywords))\n",
    "    \n",
    "    skeleton = []\n",
    "    \n",
    "    auxi = []\n",
    "    \n",
    "    # Recorro cada palabra con su tag asociado \n",
    "    \n",
    "    for pair in slogan:\n",
    "        \n",
    "        # Si el tag coincide con alguno de los acordados como parte de esqueleto, se añade la palabra a la lista de esqueleto\n",
    "        \n",
    "        if pair[1] in pos_in:\n",
    "            \n",
    "            skeleton.append(pair[0])\n",
    "            \n",
    "        # Si el tag no coincide con alguno de los acordados como parte de esqueleto, se añade el tag a la lista de auxis y a la lista de esqueletos\n",
    "           \n",
    "        else:\n",
    "            \n",
    "            skeleton.append(pair[1])\n",
    "            auxi.append(pair[1])\n",
    "            \n",
    "    # Creamos una lista con todos los esqueletos y auxiliares generados por eslogan\n",
    "    \n",
    "    allSkeletons.append(skeleton)\n",
    "    \n",
    "    allAuxis.append(auxi)\n",
    "\n",
    "# Añadimos dos columnas al datafreame inical (sloganSkeleton y sloganAuxi)\n",
    "\n",
    "slogansDF['sloganSkeleton'] = allSkeletons\n",
    "\n",
    "slogansDF['sloganAuxi'] = allAuxis\n",
    "\n",
    "slogansDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminación de filas tras una exploración visual de los datos por inviabilidad de generar eslóganes correctos a partir de ellos\n",
    "\n",
    "slogansDF = slogansDF[~slogansDF[\"slogans\"].str.contains(\"Britvic\")].reset_index(drop=True)\n",
    "\n",
    "slogansDF = slogansDF[~slogansDF[\"slogans\"].str.contains(\"Is it in you?\")].reset_index(drop=True)\n",
    "\n",
    "slogansDF = slogansDF[~slogansDF[\"slogans\"].str.contains(\"Drink Camp - its the best\")].reset_index(drop=True)\n",
    "\n",
    "slogansDF = slogansDF[~slogansDF[\"slogans\"].str.contains(\"night drink, 1960s\")].reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exploración de datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slogans</th>\n",
       "      <th>sloganTagged</th>\n",
       "      <th>sloganSkeleton</th>\n",
       "      <th>sloganAuxi</th>\n",
       "      <th>auxiCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1 makes hamburgers taste like steakburgers</td>\n",
       "      <td>[(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, like, NNS]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, NNS]</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Get the Abbey habit</td>\n",
       "      <td>[(get, VB), (the, DT), (abbey, NN), (habit, NN)]</td>\n",
       "      <td>[VB, the, NN, NN]</td>\n",
       "      <td>[VB, NN, NN]</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because life’s complicated enough</td>\n",
       "      <td>[(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]</td>\n",
       "      <td>[because, NN, NNP, NN, VBD, enough]</td>\n",
       "      <td>[NN, NNP, NN, VBD]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Access takes the waiting out of wanting</td>\n",
       "      <td>[(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]</td>\n",
       "      <td>[NN, VBZ, the, VBG, out, of, VBG]</td>\n",
       "      <td>[NN, VBZ, VBG, VBG]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Makes sensible buying simple</td>\n",
       "      <td>[(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        slogans  \\\n",
       "0  A-1 makes hamburgers taste like steakburgers   \n",
       "1  Get the Abbey habit                            \n",
       "2  Because life’s complicated enough              \n",
       "3  Access takes the waiting out of wanting        \n",
       "4  Makes sensible buying simple                   \n",
       "\n",
       "                                                                                   sloganTagged  \\\n",
       "0  [(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]    \n",
       "1  [(get, VB), (the, DT), (abbey, NN), (habit, NN)]                                               \n",
       "2  [(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]               \n",
       "3  [(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]   \n",
       "4  [(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]                                     \n",
       "\n",
       "                        sloganSkeleton                sloganAuxi  auxiCount  \n",
       "0  [JJ, VBZ, NNS, VBP, like, NNS]       [JJ, VBZ, NNS, VBP, NNS]  5          \n",
       "1  [VB, the, NN, NN]                    [VB, NN, NN]              3          \n",
       "2  [because, NN, NNP, NN, VBD, enough]  [NN, NNP, NN, VBD]        4          \n",
       "3  [NN, VBZ, the, VBG, out, of, VBG]    [NN, VBZ, VBG, VBG]       4          \n",
       "4  [VBZ, JJ, NN, NN]                    [VBZ, JJ, NN, NN]         4          "
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Añadir una columna con el conteo de las palabras auxiliares necesarias para formar el eslogan\n",
    "\n",
    "slogansDF['auxiCount'] = [len(x) for x in slogansDF.sloganAuxi]\n",
    "slogansDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograma de cantidad de palabras auxiliares por eslogan\n",
    "\n",
    "auxiCountHist = sns.countplot(x=\"auxiCount\", data=slogansDF, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.214804063860668"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Media de auxis requeridos por eslogan\n",
    "\n",
    "mean = slogansDF.auxiCount.mean()\n",
    "mean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5.0"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 3er cuartil \n",
    "\n",
    "quant = slogansDF.auxiCount.quantile(q=0.75)\n",
    "quant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Selección de las eslóganes que requieran 5 o menos palabras auxiliares pero más de 0 (si no sería plagio)\n",
    "\n",
    "slogansDF = slogansDF[slogansDF['auxiCount']<6].reset_index()\n",
    "slogansDF = slogansDF[slogansDF['auxiCount']>0].reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYgAAAEKCAYAAAAIO8L1AAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4yLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvOIA7rQAAE3pJREFUeJzt3X+wZ3V93/HnCxZEiRTIXsi6P7okXX8Qawu9MiQ0xohNwFh2m9EMpOhOpN00ocafVWjSkNYwg00bo2nqzEZWoKUQBhS21rGhCDI2AVwQEFgtO2jhZlf2GvAHMYNdffeP79m5X9bP7n53936/5y73+Zi58z3ncz7nnDfnD177OT9TVUiStKcj+i5AkrQwGRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNS3pu4BDsXTp0lq9enXfZUjSYeXee+/9RlVN7a/fYR0Qq1evZsuWLX2XIUmHlST/d5R+nmKSJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1HdZPUksH6s7bt/Zdwrx7zc+9ou8S9Dw1thFEkk1JdiZ5aI/2tyf5SpKHk/z7ofZLk2zrlv3CuOqSJI1mnCOIq4D/BFyzuyHJzwFrgVdV1bNJTuraTwXOB34SeAnwv5K8tKq+P8b6JEn7MLYRRFXdCTy1R/OvA1dU1bNdn51d+1rg+qp6tqq+CmwDzhhXbZKk/Zv0ReqXAj+T5O4kn0vy6q59OfDEUL+Zrk2S1JNJX6ReApwAnAm8GrghyY8DafSt1gaSbAA2AKxatWpMZUqSJj2CmAE+UQP3AD8AlnbtK4f6rQC2tzZQVRurarqqpqem9vu9C0nSQZp0QNwMvA4gyUuBo4FvAJuB85O8IMkpwBrgngnXJkkaMrZTTEmuA14LLE0yA1wGbAI2dbe+fg9YX1UFPJzkBuARYBdwsXcwSVK/xhYQVXXBXhZduJf+lwOXj6seSdKB8VUbkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1jS0gkmxKsrP7etyey96bpJIs7eaT5CNJtiV5MMnp46pLkjSacY4grgLO2bMxyUrgHwGPDzWfy+A71GuADcBHx1iXJGkEYwuIqroTeKqx6EPA+4AaalsLXFMDdwHHJ1k2rtokSfs30WsQSc4D/rKqHthj0XLgiaH5ma5NktSTJZPaUZIXAb8F/HxrcaOtGm0k2cDgNBSrVq2at/okSc81yRHETwCnAA8k+RqwArgvyY8xGDGsHOq7Atje2khVbayq6aqanpqaGnPJkrR4TSwgqupLVXVSVa2uqtUMQuH0qvo6sBl4a3c305nAt6pqx6RqkyT9sHHe5nod8BfAy5LMJLloH90/DTwGbAP+BPiNcdUlSRrN2K5BVNUF+1m+emi6gIvHVYsk6cD5JLUkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU1j+2CQFo6/+Zvb+i5h3r3whWf3XYL0vDfOT45uSrIzyUNDbb+f5MtJHkzyySTHDy27NMm2JF9J8gvjqkuSNJpxnmK6Cjhnj7ZbgVdW1auA/wNcCpDkVOB84Ce7df5zkiPHWJskaT/GFhBVdSfw1B5tf1ZVu7rZu4AV3fRa4PqqeraqvgpsA84YV22SpP3r8xrE24A/7aaXMwiM3Wa6th+SZAOwAWDVqlXjrE96Xpv90O/1XcK8m3rXb/ddwvNKL3cxJfktYBdw7e6mRrdqrVtVG6tquqqmp6amxlWiJC16Ex9BJFkPvBE4u6p2h8AMsHKo2wpg+6RrkyTNmegIIsk5wPuB86rqu0OLNgPnJ3lBklOANcA9k6xNkvRcYxtBJLkOeC2wNMkMcBmDu5ZeANyaBOCuqvoXVfVwkhuARxicerq4qr4/rtokSfs3toCoqgsazVfuo//lwOXjqkeSdGB81YYkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNRkQkqQmA0KS1GRASJKaDAhJUpMBIUlqMiAkSU1jC4gkm5LsTPLQUNuJSW5N8mj3e0LXniQfSbItyYNJTh9XXZKk0YxzBHEVcM4ebZcAt1XVGuC2bh7gXAbfoV4DbAA+Osa6JEkjGFtAVNWdwFN7NK8Fru6mrwbWDbVfUwN3AccnWTau2iRJ+zfpaxAnV9UOgO73pK59OfDEUL+Zrk2S1JOFcpE6jbZqdkw2JNmSZMvs7OyYy5KkxWvSAfHk7lNH3e/Orn0GWDnUbwWwvbWBqtpYVdNVNT01NTXWYiVpMZt0QGwG1nfT64Fbhtrf2t3NdCbwrd2noiRJ/Vgyrg0nuQ54LbA0yQxwGXAFcEOSi4DHgTd33T8NvAHYBnwX+NVx1SVJGs3YAqKqLtjLorMbfQu4eFy1SJIO3EinmJLcNkqbJOn5Y58jiCTHAC9icJroBObuNjoOeMmYa5Mk9Wh/p5h+DXgngzC4l7mA+Dbwx2OsS5LUs30GRFV9GPhwkrdX1R9NqCZJ0gIw0kXqqvqjJD8NrB5ep6quGVNdkqSejRQQSf4L8BPA/cD3u+YCDAhJep4a9TbXaeDU7nZUSdIiMOqT1A8BPzbOQiRJC8uoI4ilwCNJ7gGe3d1YVeeNpSpJUu9GDYjfHWcRkqSFZ9S7mD437kIkSQvLqHcxfYe57zMcDRwF/HVVHTeuwiRJ/Rp1BPHi4fkk64AzxlKRJGlBOKjvQVTVzcDr5rkWSdICMuoppl8amj2CwXMRPhMhSc9jo97F9I+HpncBXwPWzns1ktSD37/5nr5LmHf/at2hXwUY9RrEvH7hLcm7gH/GYBTyJQZfkFsGXA+cCNwHvKWqvjef+5UkjW7UDwatSPLJJDuTPJnkpiQrDmaHSZYDvwlMV9UrgSOB84EPAh+qqjXA08BFB7N9SdL8GPUi9ceBzQy+C7Ec+O9d28FaArwwyRIGHyTaweCi943d8quBdYewfUnSIRo1IKaq6uNVtav7uwqYOpgdVtVfAv8BeJxBMHyLwceIvllVu7puMwyCSJLUk1ED4htJLkxyZPd3IfBXB7PD7tOla4FTGIxIjgXObXRt3iWVZEOSLUm2zM7OHkwJkqQRjBoQbwN+Gfg6g3/1v4nBheWD8Xrgq1U1W1X/D/gE8NPA8d0pJ4AVwPbWylW1saqmq2p6auqgBjGSpBGMGhAfANZX1VRVncQgMH73IPf5OHBmkhclCXA28AhwO4PgAVgP3HKQ25ckzYNRA+JVVfX07pmqego47WB2WFV3M7gYfR+DW1yPADYC7wfenWQb8KPAlQezfUnS/Bj1QbkjkpywOySSnHgA6/6QqroMuGyP5sfw/U6StGCM+j/5/wj8eZIbGVw8/mXg8rFVJUnq3ahPUl+TZAuDZxUC/FJVPTLWyiRJvRr5NFEXCIaCJC0SB/W6b0nS858BIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ19RIQSY5PcmOSLyfZmuSnkpyY5NYkj3a/J/RRmyRpoK8RxIeBz1TVy4G/B2wFLgFuq6o1wG3dvCSpJxMPiCTHAa+h++Z0VX2vqr4JrAWu7rpdDaybdG2SpDl9jCB+HJgFPp7ki0k+luRY4OSq2gHQ/Z7UQ22SpE4fAbEEOB34aFWdBvw1B3A6KcmGJFuSbJmdnR1XjZK06PUREDPATFXd3c3fyCAwnkyyDKD73dlauao2VtV0VU1PTU1NpGBJWowmHhBV9XXgiSQv65rOZvCt683A+q5tPXDLpGuTJM1Z0tN+3w5cm+Ro4DHgVxmE1Q1JLgIeB97cU22SJHoKiKq6H5huLDp70rVIktp8klqS1GRASJKaDAhJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLU1FtAJDkyyReTfKqbPyXJ3UkeTfKn3edIJUk96XME8Q5g69D8B4EPVdUa4Gngol6qkiQBPQVEkhXALwIf6+YDvA64setyNbCuj9okSQN9jSD+EHgf8INu/keBb1bVrm5+BljeWjHJhiRbkmyZnZ0df6WStEhNPCCSvBHYWVX3Djc3ulZr/araWFXTVTU9NTU1lholSbCkh32eBZyX5A3AMcBxDEYUxydZ0o0iVgDbe6hNktSZ+Aiiqi6tqhVVtRo4H/hsVf1T4HbgTV239cAtk65NkjSnjxHE3rwfuD7J7wFfBK48lI199At3zktRC8mvv/o1fZcgaRHpNSCq6g7gjm76MeCMPuuRJM3xSWpJUpMBIUlqMiAkSU0GhCSpyYCQJDUZEJKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpomHhBJVia5PcnWJA8neUfXfmKSW5M82v2eMOnaJElz+hhB7ALeU1WvAM4ELk5yKnAJcFtVrQFu6+YlST2ZeEBU1Y6quq+b/g6wFVgOrAWu7rpdDaybdG2SpDm9XoNIsho4DbgbOLmqdsAgRICT+qtMktRbQCT5EeAm4J1V9e0DWG9Dki1JtszOzo6vQEla5HoJiCRHMQiHa6vqE13zk0mWdcuXATtb61bVxqqarqrpqampyRQsSYtQH3cxBbgS2FpVfzC0aDOwvpteD9wy6dokSXOW9LDPs4C3AF9Kcn/X9q+BK4AbklwEPA68uYfaJEmdiQdEVX0eyF4Wnz3JWiRJe+eT1JKkJgNCktRkQEiSmgwISVKTASFJajIgJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnJgJAkNS24gEhyTpKvJNmW5JK+65GkxWpBBUSSI4E/Bs4FTgUuSHJqv1VJ0uK0oAICOAPYVlWPVdX3gOuBtT3XJEmL0kILiOXAE0PzM12bJGnClvRdwB7SaKvndEg2ABu62WeSfGXsVe3fUuAb497Jb4x7B/NjIsfiMOGxmDOZY/HufzP2XcyDiRyL9+178d8eZRsLLSBmgJVD8yuA7cMdqmojsHGSRe1Pki1VNd13HQuBx2KOx2KOx2LO4XQsFtoppi8Aa5KckuRo4Hxgc881SdKitKBGEFW1K8m/BP4ncCSwqaoe7rksSVqUFlRAAFTVp4FP913HAVpQp7x65rGY47GY47GYc9gci1TV/ntJkhadhXYNQpK0QBgQhyDJpiQ7kzzUdy19SrIyye1JtiZ5OMk7+q6pL0mOSXJPkge6Y/Fv+66pb0mOTPLFJJ/qu5Y+Jflaki8luT/Jlr7rGYWnmA5BktcAzwDXVNUr+66nL0mWAcuq6r4kLwbuBdZV1SM9lzZxSQIcW1XPJDkK+Dzwjqq6q+fSepPk3cA0cFxVvbHvevqS5GvAdFUdNs/GOII4BFV1J/BU33X0rap2VNV93fR3gK0s0ifga+CZbvao7m/R/issyQrgF4GP9V2LDpwBoXmVZDVwGnB3v5X0pzulcj+wE7i1qhbtsQD+kMFDvT/ou5AFoIA/S3Jv90aIBc+A0LxJ8iPATcA7q+rbfdfTl6r6flX9fQZvAjgjyaI8/ZjkjcDOqrq371oWiLOq6nQGb6u+uDtFvaAZEJoX3fn2m4Brq+oTfdezEFTVN4E7gHN6LqUvZwHndeferwdel+S/9ltSf6pqe/e7E/gkg7dXL2gGhA5Zd2H2SmBrVf1B3/X0KclUkuO76RcCrwe+3G9V/aiqS6tqRVWtZvDanM9W1YU9l9WLJMd2N3CQ5Fjg54EFf/ejAXEIklwH/AXwsiQzSS7qu6aenAW8hcG/EO/v/t7Qd1E9WQbcnuRBBu8Wu7WqFvXtnQLgZODzSR4A7gH+R1V9puea9svbXCVJTY4gJElNBoQkqcmAkCQ1GRCSpCYDQpLUZEBIhyDJv0vy+m76qCRXJHk0yUPdW13Pnef9rU7yK/O5TWlvFtwX5aTDSVX9ztDsBxg8B/HKqno2ycnAz87zLlcDvwL8t3nervRDHEFo0Upyc/fitId3vzwtyTNDy9+U5Kpu+pYkb+2mfy3Jtd30VV2/FwH/HHh7VT0LUFVPVtUNXb8Lum8BPJTkg0P72Nv+rkrykSR/nuSxJG/qul0B/Ez3MOK7xnVsJHAEocXtbVX1VPdKjC8kuWkffTcA/zvJV4H3AGfusfzvAI+3XlKY5CXAB4F/ADzN4I2e66rq5v3Utwz4h8DLgc3AjcAlwHsX83cVNDmOILSY/Wb36oO7gJXAmr11rKongd8BbgfeU1UH8h2QVwN3VNVsVe0CrgVGeZPnzVX1g+7DSycfwP6keeEIQotSktcyeJHeT1XVd5PcARzDcz/uc8weq/1d4K+AlzQ2uQ1YleTF3UeTnrO7fZSyr/09O+I2pLFwBKHF6m8BT3fh8HLmThk9meQVSY4A/snuzknOYPAe/9OA9yY5ZXhjVfVdBm+0/UiSo7t1liW5kMHHk342ydIkRwIXAJ/b1/724TvAiw/yv1k6IAaEFqvPAEu6t65+gMFpJhic4/8U8FlgB0CSFwB/wuCaxXYG1yA2da85H/bbwCzwSJKHgJuB2araAVzK4PTUA8B9VXXL3va3Hw8Cu5I84EVqjZtvc5UkNTmCkCQ1GRCSpCYDQpLUZEBIkpoMCElSkwEhSWoyICRJTQaEJKnp/wM/FAPfX3wgMgAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograma del dataset filtrado\n",
    "\n",
    "auxiCountHist = sns.countplot(x=\"auxiCount\", data=slogansDF, palette=\"Set3\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Distribución de los tipos de tags de las palabras auxiliares\n",
    "\n",
    "ratioAuxiTags = dict.fromkeys(['nouns', 'verbs', 'adjs', 'other'])\n",
    "\n",
    "c_N=0\n",
    "c_V=0\n",
    "c_A=0\n",
    "c_O=0\n",
    "\n",
    "# Recorrer cada auxi\n",
    "for auxi in slogansDF.sloganAuxi:\n",
    "    \n",
    "    # Recorrer cada tag del auxi\n",
    "    for elem in auxi:\n",
    "        \n",
    "        # Si el tag es un nombre...\n",
    "        if elem.startswith('N'):\n",
    "            \n",
    "            # incrementa el contador y actualiza el dato de la coulmna \"nouns\"\n",
    "            c_N += 1\n",
    "            ratioAuxiTags['nouns'] = c_N\n",
    "                    \n",
    "        # Si el tag es un verbo...           \n",
    "        if elem.startswith('V'):\n",
    "            \n",
    "            # incrementa el contador y actualiza el dato de la coulmna \"verbs\"\n",
    "            c_V += 1\n",
    "            ratioAuxiTags['verbs'] = c_V\n",
    "        \n",
    "        # Si el tag es un adjetivo...        \n",
    "        if elem.startswith('J'):\n",
    "\n",
    "            # Incrementa el contador y actualiza el dato de la coulmna \"adjs\"\n",
    "            c_A += 1\n",
    "            ratioAuxiTags['adjs'] = c_A\n",
    "            \n",
    "        # Si el tag es un símbolo o carcater extraño... \n",
    "        else:\n",
    "            \n",
    "            # Incrementa el contador y actualiza el dato de la coulmna \"other\"\n",
    "            c_O += 1\n",
    "            ratioAuxiTags['other'] = c_O"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Histograma categoría de tags (nombres, verbos y adjetivos) de los auxis - other (tags de simbolos y caracteres extraños)\n",
    "\n",
    "plt.bar(ratioAuxiTags.keys(), ratioAuxiTags.values(), color='grey')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## KEYWORDS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fortune-500 descripciones\n",
    "\n",
    "# Leer y generar dataset con el nombre de las compañías\n",
    "\n",
    "#brandsF500 = pd.read_excel('brandsF500.xlsx')\n",
    "\n",
    "# Configurar el idioma de la API de Wikipedia (inglés)\n",
    "\n",
    "#wiki_wiki = wikipediaapi.Wikipedia('en')\n",
    "\n",
    "# crear una lista vacía donde se irán añadiendo cada una de las descripciones\n",
    "\n",
    "description = []\n",
    "\n",
    "# Recorrer por filas el dtaaset\n",
    "\n",
    "#for brand in brandsF500.brand:\n",
    "      \n",
    "    # Extraer el texto de cada compañía conectando con la API\n",
    "    \n",
    "    #description.append(wiki_wiki.page(brand).text)\n",
    "    \n",
    "# Crear un datframe donde cada fila contenga una descripción  \n",
    "\n",
    "#brandsF500['brandDescription'] = description\n",
    "\n",
    "# Volvar el resultado en un excel\n",
    "\n",
    "#corpus_500 = brandsF500.brandDescription.to_excel('brandDescriptions500.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Insert a brand to create a slogan from: Tesla\n"
     ]
    }
   ],
   "source": [
    "# Extraer y añadir la descripción de la compañía de la que queremos obtener el eslogan\n",
    "\n",
    "wiki_wiki = wikipediaapi.Wikipedia('en')\n",
    "\n",
    "try:\n",
    "    # Acceder a la página de Wikipedia de la compañía \n",
    "    \n",
    "    brandWiki = wiki_wiki.page(input(\"Insert a brand to create a slogan from: \"))\n",
    "    \n",
    "# En caso de que haya varias opciones, se muestran y el usuario escoge la correcta\n",
    "\n",
    "except wiki_wiki.exceptions.DisambiguationError as e:\n",
    "    \n",
    "    print('\\n',e.options)\n",
    "    \n",
    "    brandWiki = wiki_wiki.page(input(\"\\nChoose one of the above: \"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Guardamos el nombre de la compañía en una variable\n",
    "\n",
    "brandWikiTitle = brandWiki.title\n",
    "\n",
    "# Guardamos la descripción de Wikipedia de la compañía en otra variable\n",
    "\n",
    "brandWikiDescription = brandWiki.text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el Corpus\n",
    "\n",
    "# Cargar dataset Fortune500\n",
    "\n",
    "corpus500 = pd.read_excel('brandDescriptions500.xlsx')\n",
    "\n",
    "# añadimos al dataset con las descripciones de Fortune500 la descripción de la nueva compañía\n",
    "\n",
    "corpusTot = corpus500.append(pd.DataFrame({'brandDescription': [brandWikiDescription]}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TFIDF\n",
    "\n",
    "# Configuramos la función TfidfVectorizer (excluir stopwords, palabras alfanuméricas y que contengan alguna letra mayúscula)\n",
    "\n",
    "tfidfVectorizer = TfidfVectorizer(stop_words = 'english', token_pattern= r'\\b[^\\d\\W]+\\b', lowercase = False)\n",
    "\n",
    "# Aplicamos la función al corpus y guardamos el resultado en una matriz\n",
    "\n",
    "tfidfMatrix = tfidfVectorizer.fit_transform(corpusTot['brandDescription'].values.astype('U'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['wrongly', 'wrote', 'wrung', 'www', 'x', 'xcelenergy', 'xenon', 'xeriscape', 'xerographic', 'xerography']\n"
     ]
    }
   ],
   "source": [
    "# Extraemos cada una de las palabras que componenen el TF-IDF --> bowT\n",
    "\n",
    "bowT = tfidfVectorizer.get_feature_names()\n",
    "\n",
    "print(bowT[-80:-70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.02325038 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.00399731 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.03018127 0.         0.         ... 0.         0.         0.        ]\n",
      " ...\n",
      " [0.02706676 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.01109421 0.         0.         ... 0.         0.         0.        ]\n",
      " [0.         0.         0.         ... 0.         0.         0.        ]]\n"
     ]
    }
   ],
   "source": [
    "# Convertimos la matriz TF-IDF a un array\n",
    "\n",
    "listsTfidf = tfidfMatrix.toarray()\n",
    "\n",
    "print(listsTfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos el diccionario TFIDF\n",
    "\n",
    "# Cogemos sólo el último elemento del array (descripción de la nueva compañía)\n",
    "    \n",
    "listTfidf = listsTfidf[-1]\n",
    "\n",
    "# Creamos un diccionario vacío\n",
    "\n",
    "dictT = {}\n",
    "\n",
    "# Recorremos cada palabra y su posición en el bowT\n",
    "\n",
    "for index, word in enumerate(bowT):\n",
    "    \n",
    "    # Excluimos las palabras con una longitud menor o igual que dos y que contengan mayúsculas\n",
    "    \n",
    "    if len(word) > 2 and word.islower():\n",
    "        \n",
    "        # Añadimos al diccionario el TF-IDF asociado a cada palabra\n",
    "        \n",
    "        dictT[word] = listTfidf[index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abandonment</th>\n",
       "      <th>abate</th>\n",
       "      <th>abated</th>\n",
       "      <th>abatement</th>\n",
       "      <th>abbreviated</th>\n",
       "      <th>abbreviation</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zoom</th>\n",
       "      <th>zoro</th>\n",
       "      <th>zoxamide</th>\n",
       "      <th>zuf</th>\n",
       "      <th>zus</th>\n",
       "      <th>zən</th>\n",
       "      <th>électrique</th>\n",
       "      <th>études</th>\n",
       "      <th>ʃlœ</th>\n",
       "      <th>ﬂavors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 18118 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   abandon  abandoned  abandoning  abandonment  abate  abated  abatement  \\\n",
       "0  0.0      0.0        0.0         0.0          0.0    0.0     0.0         \n",
       "\n",
       "   abbreviated  abbreviation  abc   ...    zoom  zoro  zoxamide  zuf  zus  \\\n",
       "0  0.0          0.0           0.0   ...    0.0   0.0   0.0       0.0  0.0   \n",
       "\n",
       "   zən  électrique  études  ʃlœ  ﬂavors  \n",
       "0  0.0  0.0         0.0     0.0  0.0     \n",
       "\n",
       "[1 rows x 18118 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasamos de diccionario a dataframe TF-IDF\n",
    "\n",
    "tfidfFiltered = pd.DataFrame(dictT, index=[0])\n",
    "\n",
    "tfidfFiltered.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF (Count Vectorizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CountVectorizer\n",
    "\n",
    "# Configuramos la función countVectorizer (excluir stopwords, palabras alfanuméricas y que contengan alguna letra mayúscula)\n",
    "\n",
    "countVectorizer = CountVectorizer(stop_words = 'english', token_pattern= r'\\b[^\\d\\W]+\\b', lowercase = False)\n",
    "\n",
    "# Aplicamos la función a la descripción de la nueva compañía y guardamos el resultado en una matriz\n",
    "\n",
    "countMatrix = countVectorizer.fit_transform([brandWikiDescription])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Serbian', 'Superconducting', 'T', 'Teraelectronvolt', 'Tesla', 'TeslaTesla', 'They', 'US', 'Valley', 'Virginia']\n"
     ]
    }
   ],
   "source": [
    "# Extraemos cada una de las palabras que aparecen la descripción --> bowC\n",
    "\n",
    "bowC = countVectorizer.get_feature_names()\n",
    "\n",
    "print(bowC[-80:-70])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 1  2  4  1  2  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1  1\n",
      "   1  1  1  1  1  1  1  1  2  2  1  1  1  1  1  1  2 10  2  1  1  1  1  1\n",
      "   2  1  1  1  1  1 31  1  1  3  1  1  1  1  1  1  1  1  1  2  1  1  1  1\n",
      "   1  1  1  1  5  1  1  2  1  1  1  1  1  1  1  1  1  1  2  1  1  1  1  1\n",
      "   1  1  1  3  1  1  3  1  1  1  2  1  1  1  1  1  2  1  1  1  1  1  1  1\n",
      "   1  1  1  2  1  2  1  1  1  2]]\n"
     ]
    }
   ],
   "source": [
    "# Convertimos la matriz CountVectorizer en un array\n",
    "\n",
    "listCount = countMatrix.toarray()\n",
    "\n",
    "print(listCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'preserving': 1, 'project': 1, 'proposed': 2, 'refer': 1, 'refers': 1, 'resonant': 1, 'rock': 1, 'science': 1, 'seismically': 1, 'song': 1}\n"
     ]
    }
   ],
   "source": [
    "# Creamos el diccionario de CountVectorizer\n",
    "\n",
    "# Creamos un diccionario vacío\n",
    "\n",
    "dictC = {}\n",
    "\n",
    "# Recorremos cada palabra y su posición en el bowC\n",
    "\n",
    "for index, word in enumerate(bowC):\n",
    "    \n",
    "    # Excluimos las  palabras que tienen una longitud igual o menor que dos y contengan mayúsculas\n",
    "    \n",
    "    if len(word) > 2 and word.islower():\n",
    "        \n",
    "        # Creamos un diccionario con cada palabra y su conteo\n",
    "        \n",
    "        dictC[word] = listCount[0][index]\n",
    "\n",
    "print(dict(list(dictC.items())[-20:-10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>active</th>\n",
       "      <th>asteroid</th>\n",
       "      <th>automotive</th>\n",
       "      <th>band</th>\n",
       "      <th>beginning</th>\n",
       "      <th>brand</th>\n",
       "      <th>cards</th>\n",
       "      <th>circuit</th>\n",
       "      <th>coal</th>\n",
       "      <th>coil</th>\n",
       "      <th>...</th>\n",
       "      <th>space</th>\n",
       "      <th>state</th>\n",
       "      <th>symbol</th>\n",
       "      <th>technology</th>\n",
       "      <th>things</th>\n",
       "      <th>titles</th>\n",
       "      <th>town</th>\n",
       "      <th>transformer</th>\n",
       "      <th>type</th>\n",
       "      <th>unit</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   active  asteroid  automotive  band  beginning  brand  cards  circuit  coal  \\\n",
       "0  1       1         1           2     1          1      1      1        1      \n",
       "\n",
       "   coil  ...   space  state  symbol  technology  things  titles  town  \\\n",
       "0  1     ...   1      1      1       2           1       2       1      \n",
       "\n",
       "   transformer  type  unit  \n",
       "0  1            1     2     \n",
       "\n",
       "[1 rows x 66 columns]"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Pasamos de diccionario a dataframe CountVectorizer\n",
    "\n",
    "countFiltered = pd.DataFrame(dictC, index=[0])\n",
    "countFiltered"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wordcloud"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lemmatizamos la bowT para la visualización de la WordCloud\n",
    "\n",
    "# Creamo un diccionario vacío\n",
    "\n",
    "dictTLemma = {}\n",
    "\n",
    "# Creamos una lista vacía\n",
    "\n",
    "keysLemma = []\n",
    "\n",
    "# Recorremos cada key del diccionario TF-IDF\n",
    "\n",
    "for key in dictT:\n",
    "    \n",
    "    # Lematizamos la palabra\n",
    "    \n",
    "    keyLemma = nltk.stem.WordNetLemmatizer().lemmatize(key)\n",
    "\n",
    "    # Si la palabra lematizada no está contenida en la lista de keysLemma, la añadimos\n",
    "    \n",
    "    if keyLemma not in keysLemma:\n",
    "        \n",
    "        # Añadimos la palabra y el resultado del TF-IDF al diccionario vacío TF-IDF_lemmas\n",
    "        \n",
    "        dictTLemma[keyLemma] = dictT[key]\n",
    "        \n",
    "        # Añadimos la palabra a la lista de palabras lematizadas\n",
    "        \n",
    "        keysLemma.append(keyLemma)\n",
    "    \n",
    "    # Si la palabra ya existe en la lista de palabras lemmatizadas, adicionamos su valor de TF-IDF a la key correspondiente\n",
    "    \n",
    "    else: \n",
    "        \n",
    "        dictTLemma[keyLemma] += dictT[key]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Wordcloud\n",
    "\n",
    "# Configuramos la función (excluimos las stopwords, determinamos el color y tamaño de la imagen) y la aplicamos al diccionario creado con Tf-IDF de los lemas\n",
    "\n",
    "wordcloud = WordCloud(stopwords=STOPWORDS, background_color='white', width=3500,height=3000).fit_words(dictTLemma)\n",
    "\n",
    "# Visualizamos el resultado\n",
    "\n",
    "plt.figure(1,figsize=(10, 10))\n",
    "plt.imshow(wordcloud)\n",
    "plt.axis('off')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracción de Keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retomamos el diccionario original y ordenamos las palabras de mayor a menor TF-IDF\n",
    "\n",
    "topWords = Counter(dictT).most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado - Tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('microarchitecture', 'NN'), ('crater', 'NN'), ('band', 'NN'), ('titles', 'NNS'), ('pages', 'NNS'), ('film', 'NN'), ('collider', 'NN'), ('flux', 'VB'), ('honour', 'JJ'), ('particle', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Analizamos morfológicamente las palabras del diccionario TF-IDF\n",
    "\n",
    "# Aplicamos la función pos_tag a cada palabra (no seleccionamos el valor del TF-IDF) y guardamos el resultado en una lista\n",
    "\n",
    "topWordsTagged = nltk.pos_tag(((np.asarray(topWords))[:,0]))\n",
    "\n",
    "print(topWordsTagged[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('microarchitecture', 'NN'), ('crater', 'NN'), ('band', 'NN'), ('titles', 'NNS'), ('pages', 'NNS'), ('film', 'NN'), ('collider', 'NN'), ('flux', 'VB'), ('honour', 'JJ'), ('particle', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "# Filtramos por tag (seleccionamos sólo los nombres, verbos y adjetivos)\n",
    "\n",
    "# Creamos una lista vacía\n",
    "\n",
    "topWordsFiltered = []\n",
    "\n",
    "# Recorremos cada elemento de la lista topWordsTagged\n",
    "\n",
    "for pair in topWordsTagged:\n",
    "    \n",
    "    # Cremaos una lista vacía por cada elemento\n",
    "    \n",
    "    skeleton = []\n",
    "    \n",
    "    # Si el tag de la topword es un nombre, verbo o adjetivo\n",
    "    \n",
    "    if pair[1] not in pos_in:\n",
    "        \n",
    "        # Conservamos la palabra (auxiliar)\n",
    "        \n",
    "        topWordsFiltered.append(pair)\n",
    "\n",
    "print(topWordsFiltered[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17272"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topWordsFiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filtrado - Análisis de sentimiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('crater', 0.0),\n",
       " ('band', 0.0),\n",
       " ('film', 0.0),\n",
       " ('collider', 0.0),\n",
       " ('flux', 0.0),\n",
       " ('honour', 0.0),\n",
       " ('particle', 0.0),\n",
       " ('lunar', 0.0),\n",
       " ('opera', 0.0),\n",
       " ('resonant', 0.125)]"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Análisis de sentimiento de las topWords seleccionadas\n",
    "\n",
    "# Creamos un diccionario vacío para rellenar con las topWords y su score de snetimiento negativo\n",
    "\n",
    "sentiments = {}\n",
    "\n",
    "\n",
    "# Recorremos cada elemento de la lista topWordsFiltered\n",
    "\n",
    "for couple in topWordsFiltered:\n",
    "    \n",
    "    \n",
    "    # Acoplamos las palabras a los diferentes casos posibles de análisis de sentiWordNet \n",
    "    \n",
    "    try:\n",
    "        \n",
    "        # Añadimos '.n' y .01 para analizarla como sustantivo y primera acepción del término\n",
    "        \n",
    "        senti = swn.senti_synset(couple[0] + '.n' +'.01')\n",
    "        \n",
    "        # Obtenemos el score del sentimiento negativo \n",
    "        \n",
    "        sentiments[couple[0]] = senti.neg_score()\n",
    "        \n",
    "    except:\n",
    "        \n",
    "        \n",
    "        try:\n",
    "            \n",
    "            # Añadimos '.v' y .01 para analizarla como verbo y primera acepción del término\n",
    "                \n",
    "            senti = swn.senti_synset(couple[0] + '.v' +'.01')\n",
    "            \n",
    "            # Obtenemos el score del sentimiento negativo \n",
    "            \n",
    "            sentiments[couple[0]] = senti.neg_score() \n",
    "\n",
    "        except:\n",
    "            \n",
    "            \n",
    "            try:\n",
    "                \n",
    "                # Añadimos '.a' y .01 para analizarla como adjetivo y primera acepción del término\n",
    "            \n",
    "                senti = swn.senti_synset(couple[0] + '.a' +'.01')\n",
    "                \n",
    "                # Obtenemos el score del sentimiento negativo \n",
    "                    \n",
    "                sentiments[couple[0]] = senti.neg_score() \n",
    "                \n",
    "\n",
    "            except:\n",
    "                \n",
    "                try:\n",
    "                    \n",
    "                    # Añadimos '.n' y .01 para analizarla como adjetivo satélite y primera acepción del término\n",
    "                    \n",
    "                    senti = swn.senti_synset(couple[0] + '.s' +'.01')\n",
    "                    \n",
    "                    # Obtenemos el score del sentimiento negativo \n",
    "                    \n",
    "                    sentiments[couple[0]] = senti.neg_score() \n",
    "\n",
    "                except:\n",
    "             \n",
    "                    try:\n",
    "                        \n",
    "                        # Añadimos '.r' y .01 para analizarla como adjetivo y primera acepción del término\n",
    "            \n",
    "                        senti = swn.senti_synset(couple[0] + '.r' +'.01')\n",
    "                \n",
    "                        # Obtenemos el score del sentimiento negativo \n",
    "                \n",
    "                        sentiments[couple[0]] = senti.neg_score()\n",
    "            \n",
    "                    except:\n",
    "                    \n",
    "                        continue\n",
    "                        \n",
    "list(sentiments.items())[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Eliminamos las keywords que tienen score negativo mayor que cero\n",
    "\n",
    "# Recorremos cada elemento del diccionario de análisis de sentimiento negativo\n",
    "\n",
    "for index, (word, senti) in enumerate(sentiments.items()):\n",
    "    \n",
    "    # Si el sentimiento mnegativo es mayor que 0\n",
    "    \n",
    "    if senti > 0:\n",
    "        \n",
    "        # Recorremos cada elemento de topWordsFiltered\n",
    "        \n",
    "        for couple in topWordsFiltered:\n",
    "            \n",
    "            # Si la palabra con el score negativo es igual a la topWord\n",
    "            \n",
    "            if couple[0] == word:\n",
    "                \n",
    "                # Eliminamos la topWord \n",
    "                \n",
    "                topWordsFiltered.remove(couple)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15423"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(topWordsFiltered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cantidad mínima"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slogans</th>\n",
       "      <th>sloganTagged</th>\n",
       "      <th>sloganSkeleton</th>\n",
       "      <th>sloganAuxi</th>\n",
       "      <th>auxiCount</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>NNP</th>\n",
       "      <th>NNPS</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1 makes hamburgers taste like steakburgers</td>\n",
       "      <td>[(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, like, NNS]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, NNS]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Get the Abbey habit</td>\n",
       "      <td>[(get, VB), (the, DT), (abbey, NN), (habit, NN)]</td>\n",
       "      <td>[VB, the, NN, NN]</td>\n",
       "      <td>[VB, NN, NN]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because life’s complicated enough</td>\n",
       "      <td>[(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]</td>\n",
       "      <td>[because, NN, NNP, NN, VBD, enough]</td>\n",
       "      <td>[NN, NNP, NN, VBD]</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Access takes the waiting out of wanting</td>\n",
       "      <td>[(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]</td>\n",
       "      <td>[NN, VBZ, the, VBG, out, of, VBG]</td>\n",
       "      <td>[NN, VBZ, VBG, VBG]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Makes sensible buying simple</td>\n",
       "      <td>[(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        slogans  \\\n",
       "0  A-1 makes hamburgers taste like steakburgers   \n",
       "1  Get the Abbey habit                            \n",
       "2  Because life’s complicated enough              \n",
       "3  Access takes the waiting out of wanting        \n",
       "4  Makes sensible buying simple                   \n",
       "\n",
       "                                                                                   sloganTagged  \\\n",
       "0  [(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]    \n",
       "1  [(get, VB), (the, DT), (abbey, NN), (habit, NN)]                                               \n",
       "2  [(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]               \n",
       "3  [(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]   \n",
       "4  [(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]                                     \n",
       "\n",
       "                        sloganSkeleton                sloganAuxi  auxiCount  \\\n",
       "0  [JJ, VBZ, NNS, VBP, like, NNS]       [JJ, VBZ, NNS, VBP, NNS]  5           \n",
       "1  [VB, the, NN, NN]                    [VB, NN, NN]              3           \n",
       "2  [because, NN, NNP, NN, VBD, enough]  [NN, NNP, NN, VBD]        4           \n",
       "3  [NN, VBZ, the, VBG, out, of, VBG]    [NN, VBZ, VBG, VBG]       4           \n",
       "4  [VBZ, JJ, NN, NN]                    [VBZ, JJ, NN, NN]         4           \n",
       "\n",
       "  NN NNS NNP NNPS VB VBD VBG VBN VBP VBZ JJ JJR JJS  \n",
       "0  0  2   0   0    0  0   0   0   1   1   1  0   0   \n",
       "1  2  0   0   0    1  0   0   0   0   0   0  0   0   \n",
       "2  2  0   1   0    0  1   0   0   0   0   0  0   0   \n",
       "3  1  0   0   0    0  0   2   0   0   1   0  0   0   \n",
       "4  2  0   0   0    0  0   0   0   0   1   1  0   0   "
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Determinar el máximo necesario de tags de cada tipo para poder compeltar todos los esqueletos\n",
    "\n",
    "# Creamos una lista con los tags de los auxis\n",
    "\n",
    "tag_auxi = [\"NN\", \"NNS\", \"NNP\", \"NNPS\", \"VB\", \"VBD\", \"VBG\", \"VBN\", \"VBP\", \"VBZ\", \"JJ\", \"JJR\", \"JJS\"]\n",
    "\n",
    "# Creamos un dataframe vacío con columnas nombradas como la lista de tags anterior\n",
    "\n",
    "df_auxi = pd.DataFrame(columns = tag_auxi)\n",
    "\n",
    "# Recorremos cada auxi\n",
    "\n",
    "for row in slogansDF.sloganAuxi:\n",
    "    \n",
    "    # Recorremos cada elemento del auxi, hacemos su conteo y lo guardamos en un diccionario\n",
    "    \n",
    "    drow = dict((x, row.count(x)) for x in tag_auxi)\n",
    "       \n",
    "    # Añadimos el resultado al dataframe inicial\n",
    "    \n",
    "    df_auxi = df_auxi.append(drow , ignore_index=True)\n",
    "\n",
    "# Concatenamos el nuevo dataframe al inicial \n",
    "\n",
    "slogansDF = pd.concat([slogansDF, df_auxi], axis=1)\n",
    "\n",
    "# Eliminamos columnas generadas tras el procesamiento que no interesan\n",
    "\n",
    "slogansDF = slogansDF.drop([\"level_0\", \"index\"], axis = 1)\n",
    "\n",
    "slogansDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtener la cantidad mínima de keywords necesaria para poder completar el total de esqueletos generados (sumar los máximos del conteo de cada tag)\n",
    "\n",
    "totalKeywords = (slogansDF.NN.max()) + (slogansDF.NNS.max()) + (slogansDF.NNP.max()) + (slogansDF.NNPS.max()) + (slogansDF.VB.max()) + (slogansDF.VBD.max()) + (slogansDF.VBG.max()) + (slogansDF.VBN.max()) + (slogansDF.VBP.max()) + (slogansDF.VBZ.max()) + (slogansDF.JJ.max()) + (slogansDF.JJR.max()) + (slogansDF.JJS.max())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "totalKeywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracción de keywords finales (topWords)\n",
    "\n",
    "# Creamos una lista vacía\n",
    "\n",
    "topWordsFinal = []\n",
    "\n",
    "# Innicializamos variables\n",
    "\n",
    "count = 0\n",
    "\n",
    "n = 0\n",
    "ns = 0\n",
    "np = 0\n",
    "nps = 0\n",
    "vb = 0\n",
    "vbd = 0\n",
    "vbg = 0\n",
    "vbn = 0\n",
    "vbp = 0\n",
    "vbz = 0\n",
    "jj = 0\n",
    "jjr = 0\n",
    "jjs = 0\n",
    "\n",
    "# Recorremos cada elemento de TopWordsFiltered y su posición\n",
    "\n",
    "for index, word in enumerate(topWordsFiltered):\n",
    "    \n",
    "    # Si el tag de la palabra es \"NN\" y todavía no tenemos todas las \"NN\" necesarias, seleccionamos las topWord (idem para cada caso)\n",
    "    \n",
    "    if word[1] == \"NN\" and n<max(slogansDF.NN):\n",
    "        \n",
    "        # Incrementamos en 1 el contador de los sutantivos\n",
    "        n += 1\n",
    "        \n",
    "        # Añadimos a la lista la keyword y su posición (c)\n",
    "        \n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"NNS\" and ns<max(slogansDF.NNS):\n",
    "\n",
    "        ns += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"NNP\" and np<max(slogansDF.NNP):\n",
    "\n",
    "        np += 1 \n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"NNPS\" and nps<max(slogansDF.NNPS):\n",
    "\n",
    "        nps += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"VB\" and vb<max(slogansDF.VB):\n",
    "\n",
    "        vb += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"VBD\" and vbd<max(slogansDF.VBD):\n",
    "\n",
    "        vbd += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"VBG\" and vbg<max(slogansDF.VBG):\n",
    "\n",
    "        vbg += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"VBN\" and vbn<max(slogansDF.VBN):\n",
    "\n",
    "        vbn += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"VBP\" and vbp<max(slogansDF.VBP):\n",
    "\n",
    "        vbp += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"VBZ\" and vbz<max(slogansDF.VBZ):\n",
    "\n",
    "        vbz += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"JJ\" and jj<max(slogansDF.JJ):\n",
    "\n",
    "        jj += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"JJR\" and jjr<max(slogansDF.JJR):\n",
    "\n",
    "        jjr += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif word[1] == \"JJS\" and jjs<max(slogansDF.JJS):\n",
    "\n",
    "        jjs += 1\n",
    "        topWordsFinal.append([word, index])\n",
    "\n",
    "    elif count == totalKeywords:\n",
    "        \n",
    "        break\n",
    "    \n",
    "    # Cuenta el total de topWords seleccionadas\n",
    "    \n",
    "    count = n + ns + np + nps + vb + vbd + vbg + vbn + vbp + vbz + jj + jjr + jjs\n",
    "    \n",
    "    # Guardamos la posición de la última keyword\n",
    "    \n",
    "    pos_max = index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "27"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de keywords escogidas\n",
    "\n",
    "count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7531"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Cantidad de keywords recorridas\n",
    "\n",
    "pos_max"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[('microarchitecture', 'NN'), 0],\n",
       " [('crater', 'NN'), 1],\n",
       " [('band', 'NN'), 2],\n",
       " [('titles', 'NNS'), 3],\n",
       " [('pages', 'NNS'), 4],\n",
       " [('film', 'NN'), 5],\n",
       " [('flux', 'VB'), 7],\n",
       " [('honour', 'JJ'), 8],\n",
       " [('preserving', 'VBG'), 10],\n",
       " [('lunar', 'JJ'), 11],\n",
       " [('asteroid', 'JJ'), 13],\n",
       " [('proposed', 'VBD'), 15],\n",
       " [('named', 'VBD'), 21],\n",
       " [('refers', 'NNS'), 22],\n",
       " [('rock', 'VBP'), 23],\n",
       " [('abandoning', 'VBG'), 61],\n",
       " [('abbreviated', 'VBN'), 65],\n",
       " [('abnormality', 'VBP'), 77],\n",
       " [('abscesses', 'VBZ'), 87],\n",
       " [('accelerates', 'VBZ'), 112],\n",
       " [('accelerometer', 'VBP'), 117],\n",
       " [('accidents', 'VBZ'), 129],\n",
       " [('acquire', 'VB'), 193],\n",
       " [('adopt', 'VB'), 308],\n",
       " [('amplifier', 'JJR'), 595],\n",
       " [('behest', 'JJS'), 1349],\n",
       " [('keyfobs', 'NNP'), 7531]]"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topWordsFinal"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hZUKqFUPd6Ht"
   },
   "source": [
    "# Generación de Eslóganes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Embedding - Gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modelo pre-entrenado de wordEmbedding\n",
    "\n",
    "# Generamos el modelo pre-entrenado de word2vec con el fichero de GoogleNews\n",
    "\n",
    "#model = KeyedVectors.load_word2vec_format('GoogleNews-vectors-negative300.bin', binary=True)\n",
    "\n",
    "# Guardamos el modelo\n",
    "\n",
    "#pickle.dump(model, open(\"gensimModel\", 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargamos el modelo pre-entrenado de wordEmbedding\n",
    "\n",
    "gensimModel = pickle.load(open(\"gensimModel\", 'rb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos la función de similitud entre palabras \n",
    "\n",
    "# El input de la función son dos palabras\n",
    "\n",
    "def word_embedding (wd1, wd2):\n",
    "    \n",
    "    # Si alguna de las palabras no está contenida en el modelo\n",
    "    \n",
    "    if (wd1 not in gensimModel.vocab) or (wd2 not in gensimModel.vocab):\n",
    "        \n",
    "        # Se establecerá la menor similitud\n",
    "        \n",
    "        sim = -1\n",
    "        \n",
    "    # Si ambas palabras están contenidas en el modelo\n",
    "    \n",
    "    else:\n",
    "        \n",
    "        # Calculamos el grado de similitud entre palabras\n",
    "        \n",
    "        sim = gensimModel.similarity(wd1, wd2)\n",
    "        \n",
    "        # Si las palabras son idénticas, le aplicamos la menor similitud (no plagio de eslóganes!!!)\n",
    "        \n",
    "        if sim >= 0.9:\n",
    "            \n",
    "            sim = -1\n",
    "            \n",
    "    # La función devuelve el ratio de similitud\n",
    "    \n",
    "    return sim\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Selección de keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slogans</th>\n",
       "      <th>sloganTagged</th>\n",
       "      <th>sloganSkeleton</th>\n",
       "      <th>sloganAuxi</th>\n",
       "      <th>auxiCount</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>NNP</th>\n",
       "      <th>NNPS</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1 makes hamburgers taste like steakburgers</td>\n",
       "      <td>[(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, like, NNS]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, NNS]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Get the Abbey habit</td>\n",
       "      <td>[(get, VB), (the, DT), (abbey, NN), (habit, NN)]</td>\n",
       "      <td>[VB, the, NN, NN]</td>\n",
       "      <td>[VB, NN, NN]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because life’s complicated enough</td>\n",
       "      <td>[(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]</td>\n",
       "      <td>[because, NN, NNP, NN, VBD, enough]</td>\n",
       "      <td>[NN, NNP, NN, VBD]</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Access takes the waiting out of wanting</td>\n",
       "      <td>[(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]</td>\n",
       "      <td>[NN, VBZ, the, VBG, out, of, VBG]</td>\n",
       "      <td>[NN, VBZ, VBG, VBG]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Makes sensible buying simple</td>\n",
       "      <td>[(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        slogans  \\\n",
       "0  A-1 makes hamburgers taste like steakburgers   \n",
       "1  Get the Abbey habit                            \n",
       "2  Because life’s complicated enough              \n",
       "3  Access takes the waiting out of wanting        \n",
       "4  Makes sensible buying simple                   \n",
       "\n",
       "                                                                                   sloganTagged  \\\n",
       "0  [(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]    \n",
       "1  [(get, VB), (the, DT), (abbey, NN), (habit, NN)]                                               \n",
       "2  [(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]               \n",
       "3  [(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]   \n",
       "4  [(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]                                     \n",
       "\n",
       "                        sloganSkeleton                sloganAuxi  auxiCount  \\\n",
       "0  [JJ, VBZ, NNS, VBP, like, NNS]       [JJ, VBZ, NNS, VBP, NNS]  5           \n",
       "1  [VB, the, NN, NN]                    [VB, NN, NN]              3           \n",
       "2  [because, NN, NNP, NN, VBD, enough]  [NN, NNP, NN, VBD]        4           \n",
       "3  [NN, VBZ, the, VBG, out, of, VBG]    [NN, VBZ, VBG, VBG]       4           \n",
       "4  [VBZ, JJ, NN, NN]                    [VBZ, JJ, NN, NN]         4           \n",
       "\n",
       "  NN NNS NNP NNPS VB VBD VBG VBN VBP VBZ JJ JJR JJS  \n",
       "0  0  2   0   0    0  0   0   0   1   1   1  0   0   \n",
       "1  2  0   0   0    1  0   0   0   0   0   0  0   0   \n",
       "2  2  0   1   0    0  1   0   0   0   0   0  0   0   \n",
       "3  1  0   0   0    0  0   2   0   0   1   0  0   0   \n",
       "4  2  0   0   0    0  0   0   0   0   1   1  0   0   "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "slogansDF.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creamos una función que seleccione la palabra con mayor score de entre todas las topWords posibles\n",
    "\n",
    "# El input de la función es (palabra,tag) del eslogan original y (palabra,tag) de las topWords\n",
    "\n",
    "def max_score (ori_tuple, kws):\n",
    "    \n",
    "    # Guardamos la palabra del eslogan original\n",
    "    \n",
    "    ori_word = ori_tuple[0]\n",
    "    \n",
    "    # Guardamos el tag de la palabra del eslogan original\n",
    "    \n",
    "    ori_tag = ori_tuple[1]\n",
    "    \n",
    "    # inicializamos la variable winner y el score\n",
    "    \n",
    "    winner = 'hola'\n",
    "    \n",
    "    sc_best = -1\n",
    "    \n",
    "    # Recorremos todos los elementos de las topWords\n",
    "    \n",
    "    for elem in kws:\n",
    "        \n",
    "        # Si el tag de la keyword y de la palabra original del eslogan coinciden\n",
    "        \n",
    "        if elem[0][1] == ori_tag:\n",
    "            \n",
    "            # Calculamos la similitud entre ellas\n",
    "            \n",
    "            sim = word_embedding(ori_word, elem[0][0])\n",
    "            \n",
    "            # Normzaliamos la posición de la topWord\n",
    "            \n",
    "            kw_sc = (pos_max - elem[1])/pos_max\n",
    "            \n",
    "            # Aplicamos la función del score(sim + pos_normalizada)\n",
    "            \n",
    "            sc = kw_sc + sim\n",
    "            \n",
    "            # Si el score es mayor que sc_best\n",
    "            \n",
    "            if sc >= sc_best:\n",
    "                \n",
    "                # Actualizamos el valor de sc_best por el nuevo score\n",
    "                \n",
    "                sc_best = sc\n",
    "                \n",
    "                # Actualizamos la variable winner con ((topWord,tag), pos)\n",
    "                \n",
    "                winner = elem\n",
    "                \n",
    "    # Borramos de las topWords el elemento seleccionado para evitar usar la misma palabra en un mismo eslogan\n",
    "    \n",
    "    kws.remove(winner)\n",
    "    \n",
    "    \n",
    "    # La función devuelve el elemento de topWords ganador, la lista de topWords sin el elemento winner y el score\n",
    "    \n",
    "    return winner, kws, sc_best"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algoritmo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Algoritmo Generación Eslogan\n",
    "\n",
    "# Creamos dos listas vacías\n",
    "\n",
    "slogansDone = []\n",
    "scoresDone = []\n",
    "\n",
    "# Recorremos cada sloganTagged\n",
    "\n",
    "for elem in slogansDF.sloganTagged:\n",
    "    \n",
    "    # Inicializamos variables\n",
    "    \n",
    "    norm = 0\n",
    "    \n",
    "    slogan = []\n",
    "    \n",
    "    score = 0\n",
    "    \n",
    "    # Realizamos una copia de las topWords\n",
    "    \n",
    "    kws = topWordsFinal.copy()\n",
    "    \n",
    "    # Recorremos cada elemento de cada sloganTagged\n",
    "    \n",
    "    for elem2 in elem:\n",
    "        \n",
    "        # Si el tag de la palabra es un nombre, verbo o adjetivo\n",
    "        \n",
    "        if elem2[1] in tag_auxi:\n",
    "            \n",
    "            # Incrementamos la variable norm en 1\n",
    "            \n",
    "            norm += 1\n",
    "            \n",
    "            # Aplicamos la función de max_score y guardamoms el resultados en tres variables\n",
    "            \n",
    "            chosen, kws, sc_score = max_score (elem2, kws)\n",
    "            \n",
    "            # Añadimos a la varibale slogan la topWord ganadora \n",
    "            \n",
    "            slogan.append(chosen[0][0])\n",
    "            \n",
    "            # Adicionamos a la variable score, el score de todas las topWords que van formando el eslogan\n",
    "        \n",
    "            score += sc_score\n",
    "            \n",
    "        # Si el tag de la palabra no es un nombre, verbo o adjetivo   \n",
    "        \n",
    "        else:\n",
    "            \n",
    "            # Añadimos a la variable slogan la palabra del sloganTagged\n",
    "            \n",
    "            slogan.append(elem2[0])\n",
    "            \n",
    "    # Inicializamos la variable s a un espacio por cada slogan    \n",
    "    s = ' '\n",
    "    \n",
    "    # Añadimos cada eslogan generado con un espacio entre ellos\n",
    "    \n",
    "    slogansDone.append(s.join(slogan))\n",
    "    \n",
    "    # Añadimos a la lista scoresDone el score de cada eslogan generado normalziado por el número de topWords empleadas\n",
    "    \n",
    "    scoresDone.append(score/norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slogans</th>\n",
       "      <th>sloganTagged</th>\n",
       "      <th>sloganSkeleton</th>\n",
       "      <th>sloganAuxi</th>\n",
       "      <th>auxiCount</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>NNP</th>\n",
       "      <th>NNPS</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>slogansGen</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A-1 makes hamburgers taste like steakburgers</td>\n",
       "      <td>[(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, like, NNS]</td>\n",
       "      <td>[JJ, VBZ, NNS, VBP, NNS]</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>honour accelerates pages abnormality like titles</td>\n",
       "      <td>0.923054</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Get the Abbey habit</td>\n",
       "      <td>[(get, VB), (the, DT), (abbey, NN), (habit, NN)]</td>\n",
       "      <td>[VB, the, NN, NN]</td>\n",
       "      <td>[VB, NN, NN]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>acquire the crater film</td>\n",
       "      <td>1.139244</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Because life’s complicated enough</td>\n",
       "      <td>[(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]</td>\n",
       "      <td>[because, NN, NNP, NN, VBD, enough]</td>\n",
       "      <td>[NN, NNP, NN, VBD]</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>because film keyfobs crater proposed enough</td>\n",
       "      <td>0.587580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Access takes the waiting out of wanting</td>\n",
       "      <td>[(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]</td>\n",
       "      <td>[NN, VBZ, the, VBG, out, of, VBG]</td>\n",
       "      <td>[NN, VBZ, VBG, VBG]</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>microarchitecture accelerates the abandoning out of preserving</td>\n",
       "      <td>1.167139</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Makes sensible buying simple</td>\n",
       "      <td>[(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "      <td>[VBZ, JJ, NN, NN]</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>accelerates asteroid band microarchitecture</td>\n",
       "      <td>1.142807</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        slogans  \\\n",
       "0  A-1 makes hamburgers taste like steakburgers   \n",
       "1  Get the Abbey habit                            \n",
       "2  Because life’s complicated enough              \n",
       "3  Access takes the waiting out of wanting        \n",
       "4  Makes sensible buying simple                   \n",
       "\n",
       "                                                                                   sloganTagged  \\\n",
       "0  [(a-1, JJ), (makes, VBZ), (hamburgers, NNS), (taste, VBP), (like, IN), (steakburgers, NNS)]    \n",
       "1  [(get, VB), (the, DT), (abbey, NN), (habit, NN)]                                               \n",
       "2  [(because, IN), (life, NN), (’, NNP), (s, NN), (complicated, VBD), (enough, RB)]               \n",
       "3  [(access, NN), (takes, VBZ), (the, DT), (waiting, VBG), (out, IN), (of, IN), (wanting, VBG)]   \n",
       "4  [(makes, VBZ), (sensible, JJ), (buying, NN), (simple, NN)]                                     \n",
       "\n",
       "                        sloganSkeleton                sloganAuxi  auxiCount  \\\n",
       "0  [JJ, VBZ, NNS, VBP, like, NNS]       [JJ, VBZ, NNS, VBP, NNS]  5           \n",
       "1  [VB, the, NN, NN]                    [VB, NN, NN]              3           \n",
       "2  [because, NN, NNP, NN, VBD, enough]  [NN, NNP, NN, VBD]        4           \n",
       "3  [NN, VBZ, the, VBG, out, of, VBG]    [NN, VBZ, VBG, VBG]       4           \n",
       "4  [VBZ, JJ, NN, NN]                    [VBZ, JJ, NN, NN]         4           \n",
       "\n",
       "  NN NNS NNP NNPS VB VBD VBG VBN VBP VBZ JJ JJR JJS  \\\n",
       "0  0  2   0   0    0  0   0   0   1   1   1  0   0    \n",
       "1  2  0   0   0    1  0   0   0   0   0   0  0   0    \n",
       "2  2  0   1   0    0  1   0   0   0   0   0  0   0    \n",
       "3  1  0   0   0    0  0   2   0   0   1   0  0   0    \n",
       "4  2  0   0   0    0  0   0   0   0   1   1  0   0    \n",
       "\n",
       "                                                       slogansGen     score  \n",
       "0  honour accelerates pages abnormality like titles                0.923054  \n",
       "1  acquire the crater film                                         1.139244  \n",
       "2  because film keyfobs crater proposed enough                     0.587580  \n",
       "3  microarchitecture accelerates the abandoning out of preserving  1.167139  \n",
       "4  accelerates asteroid band microarchitecture                     1.142807  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creamos un dataframe con todos los eslóganes generados y su score\n",
    "\n",
    "df_auxi2 = pd.DataFrame({'slogansGen': slogansDone, 'score': scoresDone})\n",
    "\n",
    "# Concatenamos este dataframe al inicial\n",
    "\n",
    "slogansDF = pd.concat([slogansDF, df_auxi2], axis=1)\n",
    "\n",
    "slogansDF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Solución"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>slogans</th>\n",
       "      <th>sloganTagged</th>\n",
       "      <th>sloganSkeleton</th>\n",
       "      <th>sloganAuxi</th>\n",
       "      <th>auxiCount</th>\n",
       "      <th>NN</th>\n",
       "      <th>NNS</th>\n",
       "      <th>NNP</th>\n",
       "      <th>NNPS</th>\n",
       "      <th>VB</th>\n",
       "      <th>VBD</th>\n",
       "      <th>VBG</th>\n",
       "      <th>VBN</th>\n",
       "      <th>VBP</th>\n",
       "      <th>VBZ</th>\n",
       "      <th>JJ</th>\n",
       "      <th>JJR</th>\n",
       "      <th>JJS</th>\n",
       "      <th>slogansGen</th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>159</th>\n",
       "      <td>It never varies</td>\n",
       "      <td>[(it, PRP), (never, RB), (varies, NNS)]</td>\n",
       "      <td>[it, never, NNS]</td>\n",
       "      <td>[NNS]</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it never refers</td>\n",
       "      <td>1.390894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>507</th>\n",
       "      <td>Stop me and buy one</td>\n",
       "      <td>[(stop, VB), (me, PRP), (and, CC), (buy, VB), (one, CD)]</td>\n",
       "      <td>[VB, me, and, VB, one]</td>\n",
       "      <td>[VB, VB]</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>adopt me and acquire one</td>\n",
       "      <td>1.362049</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>513</th>\n",
       "      <td>Breakfast of Champions</td>\n",
       "      <td>[(breakfast, NN), (of, IN), (champions, NNS)]</td>\n",
       "      <td>[NN, of, NNS]</td>\n",
       "      <td>[NN, NNS]</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>crater of titles</td>\n",
       "      <td>1.264684</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>233</th>\n",
       "      <td>Harp puts out the fire</td>\n",
       "      <td>[(harp, NN), (puts, VBZ), (out, RP), (the, DT), (fire, NN)]</td>\n",
       "      <td>[NN, VBZ, out, the, NN]</td>\n",
       "      <td>[NN, VBZ, NN]</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>band accelerates out the crater</td>\n",
       "      <td>1.263838</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>367</th>\n",
       "      <td>It helps protect your skin.</td>\n",
       "      <td>[(it, PRP), (helps, VBZ), (protect, VB), (your, PRP$), (skin, NN), (., .)]</td>\n",
       "      <td>[it, VBZ, VB, your, NN, .]</td>\n",
       "      <td>[VBZ, VB, NN]</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>it accelerates adopt your microarchitecture .</td>\n",
       "      <td>1.253401</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         slogans  \\\n",
       "159  It never varies               \n",
       "507  Stop me and buy one           \n",
       "513  Breakfast of Champions        \n",
       "233  Harp puts out the fire        \n",
       "367  It helps protect your skin.   \n",
       "\n",
       "                                                                   sloganTagged  \\\n",
       "159  [(it, PRP), (never, RB), (varies, NNS)]                                      \n",
       "507  [(stop, VB), (me, PRP), (and, CC), (buy, VB), (one, CD)]                     \n",
       "513  [(breakfast, NN), (of, IN), (champions, NNS)]                                \n",
       "233  [(harp, NN), (puts, VBZ), (out, RP), (the, DT), (fire, NN)]                  \n",
       "367  [(it, PRP), (helps, VBZ), (protect, VB), (your, PRP$), (skin, NN), (., .)]   \n",
       "\n",
       "                 sloganSkeleton     sloganAuxi  auxiCount NN NNS NNP NNPS VB  \\\n",
       "159  [it, never, NNS]            [NNS]          1          0  1   0   0    0   \n",
       "507  [VB, me, and, VB, one]      [VB, VB]       2          0  0   0   0    2   \n",
       "513  [NN, of, NNS]               [NN, NNS]      2          1  1   0   0    0   \n",
       "233  [NN, VBZ, out, the, NN]     [NN, VBZ, NN]  3          2  0   0   0    0   \n",
       "367  [it, VBZ, VB, your, NN, .]  [VBZ, VB, NN]  3          1  0   0   0    1   \n",
       "\n",
       "    VBD VBG VBN VBP VBZ JJ JJR JJS  \\\n",
       "159  0   0   0   0   0   0  0   0    \n",
       "507  0   0   0   0   0   0  0   0    \n",
       "513  0   0   0   0   0   0  0   0    \n",
       "233  0   0   0   0   1   0  0   0    \n",
       "367  0   0   0   0   1   0  0   0    \n",
       "\n",
       "                                        slogansGen     score  \n",
       "159  it never refers                                1.390894  \n",
       "507  adopt me and acquire one                       1.362049  \n",
       "513  crater of titles                               1.264684  \n",
       "233  band accelerates out the crater                1.263838  \n",
       "367  it accelerates adopt your microarchitecture .  1.253401  "
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Ordenamos el dataframe en sentido descendente por el valor de la columna score\n",
    "\n",
    "slogansSorted = slogansDF.sort_values(by=['score'], ascending=False)\n",
    "\n",
    "slogansSorted.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Escogemos la columna del eslogan generado con el mayor score\n",
    "\n",
    "sloganGenerated = slogansSorted.iloc[0,18]\n",
    "\n",
    "# Ponemos en mayúscula la primera letra y quitamos espacios al inicio o final no deseados\n",
    "\n",
    "sloganGenerated = sloganGenerated.capitalize().strip()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'It never refers'"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sloganGenerated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Encuesta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtenemos las listas de eslóganes de percentil 0.25, 0.5 and 0.75 y seleccionamos el último en cada caso\n",
    "\n",
    "sloganQ1 = slogansSorted[slogansSorted['score'] <= slogansSorted['score'].quantile(0.25)].iloc[-1,18]\n",
    "\n",
    "sloganQ2 = slogansSorted[(slogansSorted['score'] > slogansSorted['score'].quantile(0.25)) & (slogansSorted['score'] < slogansSorted['score'].quantile(0.75))].iloc[-1,18]\n",
    "\n",
    "sloganQ3 = slogansSorted[slogansSorted['score'] >= slogansSorted['score'].quantile(0.75)].iloc[-1,18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lista con el eslogan ganador y los tres eslóganes seleccionados de cada percentil\n",
    "\n",
    "slogansSelected = [sloganGenerated, sloganQ3, sloganQ2, sloganQ1]\n",
    "\n",
    "brand = brandWikiTitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "slogansSelected"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Dataframe con la lista de eslóganes y el nombre de la primera compañía \n",
    "\n",
    "slogansPoll = pd.DataFrame({\"brand\": brand, \"slogans\": slogansSelected})\n",
    "\n",
    "slogansPoll\n",
    "\n",
    "# Exportar el resultado a un documento excel\n",
    "\n",
    "slogansPoll.to_excel('slogansPoll.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crear dataframe con los cuatro eslóganes seleccionados y la compañía (a partir de la segunda compañía)\n",
    "\n",
    "#slogansPollRe = pd.DataFrame({\"brand\": brand, \"slogans\": slogansSelected})\n",
    "\n",
    "# Concatenear el resultado de las 10 compañías en el dataframe\n",
    "\n",
    "#slogansPoll = slogansPoll.append(slogansPollRe, ignore_index = True)\n",
    "\n",
    "# Abrir y guardar en el excel (hasta tener las 10 compañias para la encuesta)\n",
    "\n",
    "#slogansPoll = pd.read_excel('slogansPoll.xlsx')\n",
    "\n",
    "#slogansPoll.to_excel('slogansPoll.xlsx')"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "SloganGenerator.ipynb",
   "provenance": [],
   "toc_visible": true,
   "version": "0.3.2"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
